{"format": "torch", "nodes": [{"name": "transformer", "id": 2315919475272, "class_name": "TransformerModel(\n  (po_embed): Embedding(90, 1)\n  (drop_em): Dropout(p=0.1, inplace=False)\n  (blocks): ModuleList(\n    (0): Block(\n      (attn): Attention(\n        (query_key): Conv1d(31, 496, kernel_size=(1,), stride=(1,))\n        (value): Conv1D()\n        (c_proj): Conv1D()\n        (attn_dropout): Dropout(p=0.1, inplace=False)\n        (resid_dropout): Dropout(p=0.1, inplace=False)\n      )\n      (ln_1): LayerNorm()\n      (mlp): MLP(\n        (c_fc): Conv1D()\n        (c_proj): Conv1D()\n        (act): ReLU()\n        (dropout): Dropout(p=0.1, inplace=False)\n      )\n      (ln_2): LayerNorm()\n    )\n    (1): Block(\n      (attn): Attention(\n        (query_key): Conv1d(31, 496, kernel_size=(1,), stride=(1,))\n        (value): Conv1D()\n        (c_proj): Conv1D()\n        (attn_dropout): Dropout(p=0.1, inplace=False)\n        (resid_dropout): Dropout(p=0.1, inplace=False)\n      )\n      (ln_1): LayerNorm()\n      (mlp): MLP(\n        (c_fc): Conv1D()\n        (c_proj): Conv1D()\n        (act): ReLU()\n        (dropout): Dropout(p=0.1, inplace=False)\n      )\n      (ln_2): LayerNorm()\n    )\n    (2): Block(\n      (attn): Attention(\n        (query_key): Conv1d(31, 496, kernel_size=(1,), stride=(1,))\n        (value): Conv1D()\n        (c_proj): Conv1D()\n        (attn_dropout): Dropout(p=0.1, inplace=False)\n        (resid_dropout): Dropout(p=0.1, inplace=False)\n      )\n      (ln_1): LayerNorm()\n      (mlp): MLP(\n        (c_fc): Conv1D()\n        (c_proj): Conv1D()\n        (act): ReLU()\n        (dropout): Dropout(p=0.1, inplace=False)\n      )\n      (ln_2): LayerNorm()\n    )\n    (3): Block(\n      (attn): Attention(\n        (query_key): Conv1d(31, 496, kernel_size=(1,), stride=(1,))\n        (value): Conv1D()\n        (c_proj): Conv1D()\n        (attn_dropout): Dropout(p=0.1, inplace=False)\n        (resid_dropout): Dropout(p=0.1, inplace=False)\n      )\n      (ln_1): LayerNorm()\n      (mlp): MLP(\n        (c_fc): Conv1D()\n        (c_proj): Conv1D()\n        (act): ReLU()\n        (dropout): Dropout(p=0.1, inplace=False)\n      )\n      (ln_2): LayerNorm()\n    )\n    (4): Block(\n      (attn): Attention(\n        (query_key): Conv1d(31, 496, kernel_size=(1,), stride=(1,))\n        (value): Conv1D()\n        (c_proj): Conv1D()\n        (attn_dropout): Dropout(p=0.1, inplace=False)\n        (resid_dropout): Dropout(p=0.1, inplace=False)\n      )\n      (ln_1): LayerNorm()\n      (mlp): MLP(\n        (c_fc): Conv1D()\n        (c_proj): Conv1D()\n        (act): ReLU()\n        (dropout): Dropout(p=0.1, inplace=False)\n      )\n      (ln_2): LayerNorm()\n    )\n  )\n)", "parameters": [["po_embed.weight", [90, 1]], ["blocks.0.attn.query_key.weight", [496, 31, 1]], ["blocks.0.attn.query_key.bias", [496]], ["blocks.0.attn.value.w", [31, 248]], ["blocks.0.attn.value.b", [248]], ["blocks.0.attn.c_proj.w", [248, 31]], ["blocks.0.attn.c_proj.b", [31]], ["blocks.0.ln_1.g", [31]], ["blocks.0.ln_1.b", [31]], ["blocks.0.mlp.c_fc.w", [31, 124]], ["blocks.0.mlp.c_fc.b", [124]], ["blocks.0.mlp.c_proj.w", [124, 31]], ["blocks.0.mlp.c_proj.b", [31]], ["blocks.0.ln_2.g", [31]], ["blocks.0.ln_2.b", [31]], ["blocks.1.attn.query_key.weight", [496, 31, 1]], ["blocks.1.attn.query_key.bias", [496]], ["blocks.1.attn.value.w", [31, 248]], ["blocks.1.attn.value.b", [248]], ["blocks.1.attn.c_proj.w", [248, 31]], ["blocks.1.attn.c_proj.b", [31]], ["blocks.1.ln_1.g", [31]], ["blocks.1.ln_1.b", [31]], ["blocks.1.mlp.c_fc.w", [31, 124]], ["blocks.1.mlp.c_fc.b", [124]], ["blocks.1.mlp.c_proj.w", [124, 31]], ["blocks.1.mlp.c_proj.b", [31]], ["blocks.1.ln_2.g", [31]], ["blocks.1.ln_2.b", [31]], ["blocks.2.attn.query_key.weight", [496, 31, 1]], ["blocks.2.attn.query_key.bias", [496]], ["blocks.2.attn.value.w", [31, 248]], ["blocks.2.attn.value.b", [248]], ["blocks.2.attn.c_proj.w", [248, 31]], ["blocks.2.attn.c_proj.b", [31]], ["blocks.2.ln_1.g", [31]], ["blocks.2.ln_1.b", [31]], ["blocks.2.mlp.c_fc.w", [31, 124]], ["blocks.2.mlp.c_fc.b", [124]], ["blocks.2.mlp.c_proj.w", [124, 31]], ["blocks.2.mlp.c_proj.b", [31]], ["blocks.2.ln_2.g", [31]], ["blocks.2.ln_2.b", [31]], ["blocks.3.attn.query_key.weight", [496, 31, 1]], ["blocks.3.attn.query_key.bias", [496]], ["blocks.3.attn.value.w", [31, 248]], ["blocks.3.attn.value.b", [248]], ["blocks.3.attn.c_proj.w", [248, 31]], ["blocks.3.attn.c_proj.b", [31]], ["blocks.3.ln_1.g", [31]], ["blocks.3.ln_1.b", [31]], ["blocks.3.mlp.c_fc.w", [31, 124]], ["blocks.3.mlp.c_fc.b", [124]], ["blocks.3.mlp.c_proj.w", [124, 31]], ["blocks.3.mlp.c_proj.b", [31]], ["blocks.3.ln_2.g", [31]], ["blocks.3.ln_2.b", [31]], ["blocks.4.attn.query_key.weight", [496, 31, 1]], ["blocks.4.attn.query_key.bias", [496]], ["blocks.4.attn.value.w", [31, 248]], ["blocks.4.attn.value.b", [248]], ["blocks.4.attn.c_proj.w", [248, 31]], ["blocks.4.attn.c_proj.b", [31]], ["blocks.4.ln_1.g", [31]], ["blocks.4.ln_1.b", [31]], ["blocks.4.mlp.c_fc.w", [31, 124]], ["blocks.4.mlp.c_fc.b", [124]], ["blocks.4.mlp.c_proj.w", [124, 31]], ["blocks.4.mlp.c_proj.b", [31]], ["blocks.4.ln_2.g", [31]], ["blocks.4.ln_2.b", [31]]], "output_shape": [[64, 90, 31]], "num_parameters": [90, 15376, 496, 7688, 248, 7688, 31, 31, 31, 3844, 124, 3844, 31, 31, 31, 15376, 496, 7688, 248, 7688, 31, 31, 31, 3844, 124, 3844, 31, 31, 31, 15376, 496, 7688, 248, 7688, 31, 31, 31, 3844, 124, 3844, 31, 31, 31, 15376, 496, 7688, 248, 7688, 31, 31, 31, 3844, 124, 3844, 31, 31, 31, 15376, 496, 7688, 248, 7688, 31, 31, 31, 3844, 124, 3844, 31, 31, 31]}, {"name": "mu", "id": 2315919873032, "class_name": "Linear(in_features=31, out_features=1, bias=True)", "parameters": [["weight", [1, 31]], ["bias", [1]]], "output_shape": [[64, 90, 1]], "num_parameters": [31, 1]}, {"name": "sigma", "id": 2315919873288, "class_name": "Linear(in_features=31, out_features=1, bias=True)", "parameters": [["weight", [1, 31]], ["bias", [1]]], "output_shape": [[64, 90, 1]], "num_parameters": [31, 1]}, {"name": "forecast_len_layer", "id": 2315919746184, "class_name": "Linear(in_features=90, out_features=30, bias=True)", "parameters": [["weight", [30, 90]], ["bias", [30]]], "output_shape": [[64, 1, 30]], "num_parameters": [2700, 30]}], "edges": []}