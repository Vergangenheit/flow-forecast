{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flood_forecast.deployment.inference import InferenceMode\n",
    "from datetime import datetime\n",
    "from typing import Dict, List\n",
    "import os\n",
    "import pandas as pd\n",
    "from pandas import DataFrame, Series, DatetimeIndex\n",
    "import wandb\n",
    "import numpy as np\n",
    "from predict import predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_config_file_infer(file_path: str, df_len: int) -> Dict:\n",
    "    \"\"\"sample of a config object for the inference case\"\"\"\n",
    "    train_number: float = df_len * .7\n",
    "    validation_number: float = df_len * .9\n",
    "    config_default = {\n",
    "        \"model_name\": \"DecoderTransformer\",\n",
    "        \"model_type\": \"PyTorch\",\n",
    "        \"takes_target\": False,\n",
    "        \"model_params\": {\n",
    "            \"n_time_series\": 30,\n",
    "            \"n_head\": 8,\n",
    "            \"forecast_history\": 120,\n",
    "            \"n_embd\": 1,\n",
    "            \"num_layer\": 5,\n",
    "            \"dropout\": 0.1,\n",
    "            \"q_len\": 1,\n",
    "            \"scale_att\": False,\n",
    "            \"forecast_length\": 30,\n",
    "            \"additional_params\": {}\n",
    "        },\n",
    "        \"dataset_params\":\n",
    "            {\n",
    "                \"class\": \"default\",\n",
    "                \"training_path\": file_path,\n",
    "                \"validation_path\": file_path,\n",
    "                \"test_path\": file_path,\n",
    "                \"batch_size\": 64,\n",
    "                \"forecast_history\": 120,\n",
    "                \"forecast_length\": 30,\n",
    "                \"train_end\": int(train_number),\n",
    "                \"valid_start\": int(train_number + 1),\n",
    "                \"valid_end\": int(validation_number),\n",
    "                \"target_col\": ['Austria'],\n",
    "                \"relevant_cols\": ['Austria', 'Belgium', 'Bulgaria', 'Switzerland', 'Czechia',\n",
    "                                  'Germany', 'Denmark', 'Estonia', 'Spain', 'Finland', 'France', 'Greece',\n",
    "                                  'Croatia', 'Hungary', 'Ireland', 'Italy', 'Lithuania', 'Luxembourg',\n",
    "                                  'Latvia', 'Netherlands', 'Norway', 'Poland', 'Portugal', 'Romania',\n",
    "                                  'Slovenia', 'Slovakia', 'Sweden', 'United Kingdom', 'month', 'weekday'],\n",
    "                \"scaler\": \"StandardScaler\",\n",
    "                \"interpolate\": False,\n",
    "                \"sort_column\": \"time\",\n",
    "            },\n",
    "        \"training_params\":\n",
    "            {\n",
    "                \"criterion\": \"DilateLoss\",\n",
    "                \"optimizer\": \"Adam\",\n",
    "                \"optim_params\":\n",
    "                    {\n",
    "                    },\n",
    "                \"lr\": 0.001,\n",
    "                \"epochs\": 100,\n",
    "                \"batch_size\": 64\n",
    "            },\n",
    "        \"early_stopping\": {\n",
    "            \"patience\": 3\n",
    "        },\n",
    "        \"GCS\": False,\n",
    "        \"sweep\": False,\n",
    "        \"wandb\": False,\n",
    "        \"forward_params\": {},\n",
    "        \"metrics\": [\"DilateLoss\"],\n",
    "        \"inference_params\":\n",
    "            {\n",
    "                \"datetime_start\": \"2013-05-01\",\n",
    "                \"hours_to_forecast\": 30,\n",
    "                \"test_csv_path\": file_path,\n",
    "                \"decoder_params\": {\n",
    "                    \"decoder_function\": \"simple_decode\",\n",
    "                    \"unsqueeze_dim\": 1\n",
    "                },\n",
    "                \"dataset_params\": {\n",
    "                    \"file_path\": file_path,\n",
    "                    \"forecast_history\": 120,\n",
    "                    \"forecast_length\": 30,\n",
    "                    \"relevant_cols\": ['Austria', 'Belgium', 'Bulgaria', 'Switzerland', 'Czechia',\n",
    "                                      'Germany', 'Denmark', 'Estonia', 'Spain', 'Finland', 'France', 'Greece',\n",
    "                                      'Croatia', 'Hungary', 'Ireland', 'Italy', 'Lithuania', 'Luxembourg',\n",
    "                                      'Latvia', 'Netherlands', 'Norway', 'Poland', 'Portugal', 'Romania',\n",
    "                                      'Slovenia', 'Slovakia', 'Sweden', 'United Kingdom', 'month', 'weekday'],\n",
    "                    \"target_col\": ['Austria'],\n",
    "                    \"scaling\": \"StandardScaler\",\n",
    "                    \"interpolate_param\": False\n",
    "                }\n",
    "            },\n",
    "    }\n",
    "\n",
    "    return config_default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path: str = '../data/wind_train.csv'\n",
    "full_len: int = len(pd.read_csv(file_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_path: str = r'C:\\Users\\Lorenzo\\PycharmProjects\\flow-forecast\\notebooks'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INFERENCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose date\n",
    "forecast_history: int = 120\n",
    "forecast_length: int = 30\n",
    "start_pred_date = datetime(2013, 5, 3)\n",
    "config: Dict = make_config_file_infer(file_path, full_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using model  <class 'flood_forecast.transformer_xl.transformer_bottleneck.DecoderTransformer'>\n",
      "Weights sucessfully loaded\n",
      "interpolate should be below\n",
      "[]\n",
      "Now loading ../data/wind_train.csv\n",
      "scaling now\n",
      "interpolate should be below\n",
      "[]\n",
      "Now loading ../data/wind_train.csv\n",
      "scaling now\n",
      "interpolate should be below\n",
      "[]\n",
      "Now loading ../data/wind_train.csv\n",
      "scaling now\n",
      "Using Wandb config:\n",
      "<function PreInitCallable.<locals>.preinit_wrapper at 0x000002655067A798>\n",
      "Torch is using cuda\n",
      "This model is currently forecasting for : 1 targets\n",
      "interpolate should be below\n",
      "[]\n",
      "Now loading ../data/wind_train.csv\n",
      "scaling now\n",
      "CSV Path below\n",
      "../data/wind_train.csv\n",
      "Add debugging crap below\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Add debugging crap below\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "df_preds: DataFrame = predict(forecast_history, forecast_length, config, file_path, ckpt_path, start_pred_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SHOW PREDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>preds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9984</th>\n",
       "      <td>2013-05-03</td>\n",
       "      <td>0.148954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9985</th>\n",
       "      <td>2013-05-04</td>\n",
       "      <td>0.215144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9986</th>\n",
       "      <td>2013-05-05</td>\n",
       "      <td>0.179264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9987</th>\n",
       "      <td>2013-05-06</td>\n",
       "      <td>0.148247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9988</th>\n",
       "      <td>2013-05-07</td>\n",
       "      <td>0.173034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9989</th>\n",
       "      <td>2013-05-08</td>\n",
       "      <td>0.103370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9990</th>\n",
       "      <td>2013-05-09</td>\n",
       "      <td>0.177954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9991</th>\n",
       "      <td>2013-05-10</td>\n",
       "      <td>0.181120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9992</th>\n",
       "      <td>2013-05-11</td>\n",
       "      <td>0.164337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9993</th>\n",
       "      <td>2013-05-12</td>\n",
       "      <td>0.167808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9994</th>\n",
       "      <td>2013-05-13</td>\n",
       "      <td>0.204728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>2013-05-14</td>\n",
       "      <td>0.130927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>2013-05-15</td>\n",
       "      <td>0.167515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>2013-05-16</td>\n",
       "      <td>0.224977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>2013-05-17</td>\n",
       "      <td>0.196486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>2013-05-18</td>\n",
       "      <td>0.195768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10000</th>\n",
       "      <td>2013-05-19</td>\n",
       "      <td>0.116399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10001</th>\n",
       "      <td>2013-05-20</td>\n",
       "      <td>0.167585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10002</th>\n",
       "      <td>2013-05-21</td>\n",
       "      <td>0.156575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10003</th>\n",
       "      <td>2013-05-22</td>\n",
       "      <td>0.209761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10004</th>\n",
       "      <td>2013-05-23</td>\n",
       "      <td>0.210761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10005</th>\n",
       "      <td>2013-05-24</td>\n",
       "      <td>0.199433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10006</th>\n",
       "      <td>2013-05-25</td>\n",
       "      <td>0.119739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10007</th>\n",
       "      <td>2013-05-26</td>\n",
       "      <td>0.187163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10008</th>\n",
       "      <td>2013-05-27</td>\n",
       "      <td>0.189384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10009</th>\n",
       "      <td>2013-05-28</td>\n",
       "      <td>0.186022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10010</th>\n",
       "      <td>2013-05-29</td>\n",
       "      <td>0.179901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10011</th>\n",
       "      <td>2013-05-30</td>\n",
       "      <td>0.230135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10012</th>\n",
       "      <td>2013-05-31</td>\n",
       "      <td>0.204674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10013</th>\n",
       "      <td>2013-06-01</td>\n",
       "      <td>0.170737</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        datetime     preds\n",
       "9984  2013-05-03  0.148954\n",
       "9985  2013-05-04  0.215144\n",
       "9986  2013-05-05  0.179264\n",
       "9987  2013-05-06  0.148247\n",
       "9988  2013-05-07  0.173034\n",
       "9989  2013-05-08  0.103370\n",
       "9990  2013-05-09  0.177954\n",
       "9991  2013-05-10  0.181120\n",
       "9992  2013-05-11  0.164337\n",
       "9993  2013-05-12  0.167808\n",
       "9994  2013-05-13  0.204728\n",
       "9995  2013-05-14  0.130927\n",
       "9996  2013-05-15  0.167515\n",
       "9997  2013-05-16  0.224977\n",
       "9998  2013-05-17  0.196486\n",
       "9999  2013-05-18  0.195768\n",
       "10000 2013-05-19  0.116399\n",
       "10001 2013-05-20  0.167585\n",
       "10002 2013-05-21  0.156575\n",
       "10003 2013-05-22  0.209761\n",
       "10004 2013-05-23  0.210761\n",
       "10005 2013-05-24  0.199433\n",
       "10006 2013-05-25  0.119739\n",
       "10007 2013-05-26  0.187163\n",
       "10008 2013-05-27  0.189384\n",
       "10009 2013-05-28  0.186022\n",
       "10010 2013-05-29  0.179901\n",
       "10011 2013-05-30  0.230135\n",
       "10012 2013-05-31  0.204674\n",
       "10013 2013-06-01  0.170737"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_preds: DataFrame = df_preds[['datetime', 'preds']]\n",
    "df_preds.tail(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "flood-forecast",
   "language": "python",
   "name": "flood-forecast"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
